---
layout: single
title : "[인과추론] Causal Impact를 활용한 인과효과 분석"
author_profile: true
read_time: false
comments: true
categories:
- CausalInference
---

<br>
<br>



새롭게 피쳐가 도입되면 그 피쳐에 대한 성과를 분석하듯이, 새롭게 모델이 도입되면 그 모델이 지표 상승에 얼마나 기여했는지 측정하는것이 필요합니다.
이번 글에서는 Causal Impact 방법론을 사용하여 인과 효과를 측정해본 경험을 작성해보았습니다.

Google 에서 만든 [**Causal Impact](https://github.com/WillianFuks/tfcausalimpact/tree/master)** 라이브러리를 사용하여 모델이 적용되지 않았을 때의 잠재적 결과 (Counterfactual) 를 예측하여 실제값과의 차이를 계산하고, 
이를 통해 모델이 얼만큼 결과변수에 영향을 주었는지 정량적 성과를 측정하려고합니다.

이론적인 내용보다는 실제 데이터에 적용해보았을때 어떤 부분을 고민했고 어떤 한계점들이 있었는지의 경험 위주로 작성했습니다.

참고로, 인과효과를 측정하는 또 다른 방법으로 DID(Difference-in-differences) 라는 방법론도 있는데 이 방법을 사용하려면 이벤트가 적용된 실험군과 이벤트가 적용되지 않은 대조군이 있어야 합니다.
하지만 이번에 도입된 모델은 특정 타겟 대상으로만 도입이 된것이 아니라, 전체 적용 되었기 때문에 대조군이 없는 상황이었습니다.
따라서 , 선택의 여지 없이 Causal Impact 방법을 사용하게 되었습니다.

<br>
<br>

# 1. Causal Impact 작동 원리

---

Causal Impact 는 구조적 시계열 모형이라고 불리는 Bayesian Structural Time Series(BSTS) 모델을 시계열 관측치에 적합시킨 다음,
counterfactual 에 대해 사후추론을 하는 방식으로 작동합니다.

다시한번 좀더 쉽게 말하면,

> 베이지안 구조적 시계열 모형을 사용해서 , 만약 특정 시점에 이벤트가 발생하지 않았다면 그 이후 지표가 어떻게 되었을지(counterfactual)를 예측하고
이 예측 결과와 실제 결과를 두고 인과 효과를 추정하는 방법입니다.
> 

<br>

### BSTS 모델 장점

시계열 예측 모델로 여러가지가 있는데, 그중에서 BSTS 가 갖고있는 장점이 무엇이길래 이걸 사용하는지가 궁금해서 찾아보았습니다.

1. **유연성**
    1. BSTS 모델은 다양한 시계열 데이터 패턴과 구조를 모델링할 수 있습니다. 이 모델은 추세, 계절성, 주기성 및 다른 패턴을 포함하여 다양한 시계열 특성을 고려할 수 있습니다.
2. **베이지안 프레임워크**
    1. BSTS는 베이지안 프레임워크에서 작동하므로 사전 지식과 가정을 모델에 통합할 수 있습니다. 이를 통해 모델을 더 정확하게 조정하고 불확실성을 관리할 수 있습니다.
3. **추가적인 공변량**
    1. BSTS 모델은 선형 공변량을 포함할 수 있어서, 종속 변수에 영향을 미칠 수 있는 외부 변수를 모델에 통합할 수 있습니다. 이는 예측의 정확성을 향상시킬 수 있습니다.
4. **Counterfactual**
    1. BSTS는 counterfactual을 추정할 수 있어서, 특정 사건이 시계열 데이터에 어떤 영향을 미치는지 알수있고, 이는 인과 관계를 파악하는데 유용합니다.
5. **다양한 모델 통합**
    1.  BSTS 모델은 ARIMA, SARIMAX, Holt-Winters와 같은 다른 시계열 모델의 일반화로 사용될 수 있으며, 이러한 모델들을 포함하여 다양한 시계열 분석 방법을 통합하여 사용할 수 있습니다.


<br>
<br>

# 2. 목표 지표

---

모델이 도입됨으로써, 개선될것을 기대하는 지표는 main지표 1개, sub지표 2개로 잡았습니다.
일반적으로 Causal Impact 를 사용한 다른 블로그 글에서는 모두 지표를 하나만을 지정했지만, 실제 현업에서는 main지표에는 얼마나 영향을 미쳤고
그 외 sub 지표에는 얼마나 영향을 미쳤는지 궁금한게 많기때문에…ㅎㅎ

그리고 만약 main 지표에는 영향이 없었지만, sub 지표에는 영향이 있었다면 이것만으로 의미가 있다고 생각해서 목표 지표를 여러개 잡고 각각에 대한 모델을 만들었습니다.


<br>
<br>

# 3. 활용 데이터

---

### 3-1. 기간 선정

- 이벤트 발생 이전 시점 (pre-period) 과 이후 시점(post-period )을 지정해줘야 합니다.
참고로, 이벤트 발생 이후 데이터가 너무 길거나 너무 짧을경우, 모델이 통계적으로 유의미한지를 판단하기 어려울 수 있기 때문에 적당한(?) 기간을 분석가가 판단해야 합니다.
- 저는 모델 도입 전 6개월반, 모델 도입 후 1개월반 정도의 기간으로 데이터를 준비했습니다.

<br>

### 3-2. 공변량 변수 선정

```
💡 Causal Impact 를 적용할때 , 공변량 변수를 어떤것으로 할것인지를 정하는것이 가장 중요하다고 생각합니다.
공변량 변수에 어떤값을 넣거나 뺐을때 결과가 완전히 달라지는 경우도 있기 때문에 , 시간이 걸리더라도 함께 일하는 동료와 충분히 논의를 해서 정하는게 좋습니다.
(다시한번 방법론보다는 도메인 지식이 가장 중요하다는것을 깨달았습니다…)
```

- **공변량 조건**
    - 모델이 이벤트가 발생하지 않았다면 나타냈을 결과 지표를 잘 예측하기위해 필요한 변수를 선정해야됩니다.
        - **(중요!)** **공변량으로 넣는 변수가 우리가 효과를 확인하고자 하는 개입과는 관련이 없어야 합니다. 왜냐하면 우리는 ‘개입이 없는’ 상태에서의 지표 변화를 예측하는 것이기 때문에.**
            - *예를들어, 목표지표를 ‘신규 고객의 구매 전환률’로 정했는데 공변량으로 ‘기존 고객의 구매 전환률’ 을 넣으면 안됨. 왜냐면 타겟이 신규 전환률이라고 해도 기존고객도 영향을 받을 수 있기 때문에.*
- **공변량 선택한 기준**
    - 상관계수를 구해보고 높은것 위주로 포함시키긴 했는데 주관적 판단으로 목표변수를 예측하는데 도움이 된다고 생각되는 변수라면 상관계수가 덜 높더라도 반영했고, 목표변수 예측에 도움되지 않을거라고 생각되는 변수는 상관계수가 크더라도 반영하지 않았습니다.
    
    ![png](/images/2023-10-03-CausalImpact_files/Untitled 0.png) 
    
- **후보 변수**
    - 목표변수를 예측하는데 도움이 된다고 생각하는 변수를 펼쳐놓고 상관계수를 보면서 최종적으로 5~7개 정도 변수를 추려서 공변량 변수로 선정했습니다.

**< 참고 > input data format**

- 목표변수를 첫번째 열에 두고, 공변량을 그 뒤에 두어야합니다.
    
    ![png](/images/2023-10-03-CausalImpact_files/Untitled 1.png) 
    

<br>
<br>


# 4. 분석

---

1. **목표 지표 시각화**
    1. 목표 지표가 특정 이벤트가 발생한 이후 어떤 변화가 있는지 시각적으로 먼저 확인해보았습니다. 
    ~~(사실, 이거저거 복잡한거 안해보고 이것만봐도 + 또는 - 효과가 있었는지는 판단이 가능하다고 생각합니다.. 다만, 좀더 논리적으로 이 결과를 설명하기위해 방법론들이 도움을 주는 역할을 하는게 아닐까 …)~~
2. **Data Normalization (z-score)**
    1. z-score는 각 X값과 평균값 사이의 거리를 모집단의 표준편차 (σ)로 나누어 준 값이기 때문에 각각의 값이 전체 분포에서 상대적 위치를 나타내게 됩니다.
    
    ```python
    # Python Code
    import scipy.stats as stats
    ci_data_zscore = pd.concat([ci_data['ratio'],stats.zscore(ci_data.iloc[:,1:])],axis=1)
    ```
    
3. **Causal Impact 결과 및 해석 방법**
    1. **데이터 input**
        1. 위에서 정한 main지표 1개와 sub지표 2개 각각을 반응변수로 두고, 각각에 대해 선정한 공변량 변수를 input으로 넣어 Causal Impact 모형을 만들고 결과를 해석해보았습니다.
            1. 신뢰구간이 0을 포함하지 않고, p-value가 통계적으로 유의하게 나오면 해당 수치가 어느정도 믿을만한 수치라고 해석이 가능합니다.
        
        ```python
        # Python Code
        ci = CausalImpact(ci_data_zscore, pre_period, post_period)
        print(ci.summary())
        print(ci.summary(output='report'))
        ci.plot()
        # ci.trained_model.summary()
        ```
        
    2. **결과 해석 방법**
        1. 도표
            1. 만약, Prediction값이 60 인데 Actual값이 70 이면, 어떤 이벤트가 발생하지 않았다면 나타났을 목표지표의 값은 60인데 이벤트가 발생함으로써 실제로는 70이 되었다고 해석할 수 있습니다.
            2. Absolute effect 는 실제값과 예측값의 차이를 나타냅니다. 위 예시로 들면 Absolute effect = 10 (70-60)
            3. Relative effect 는 이 차이에 대한 비율값을 의미합니다. 위 예시로 들면 Relative effect = 16.7% ((70-60)*100/60)
            4. Posterior tail-area probability 는 우리가 알고있는 p-value를 의미합니다.
            5. Posterior prob. of a causal effect 는 아래의 경우 일반적인 5% 유의수준일때 100%의 확률로 결과를 신뢰할 수 있다는것을 의미합니다.
                
                ![png](/images/2023-10-03-CausalImpact_files/Untitled 2.png) 
                
        2. 차트
            1. 첫번째 그래프
                1. 검은색선 : 이미 관측된 실제값
                2. 파란색 점선 : Counterfactual 예측값
            2. 두번째 그래프
                1. 실제값과 예측값 간의 차이
            3. 세번째 그래프
                1. 파란색 점선 : 실제값 / 예측값 간의 차이의 누적값을 보여줌
                2. 파란색 구간 : 95% 신뢰수준에서 결과값 구간을 보여줌
                    
                    ![png](/images/2023-10-03-CausalImpact_files/Untitled 3.png) 

<br>
<br>      



# 5. Back-test

---

### 5-1. Back-test 결과

- CausalImpact 모형이 잘 만들어졌는지를 확인하기위해 Back-test를 진행합니다.
이벤트가 발생한 일자가 아닌 다른일자를 랜덤으로 지정해서 pre_period , post_period를 나누어 모형을 학습하고 결과를 확인합니다.
    - 이때 counterfactual 예측값과 실제값이 비슷해서 통계적으로 유의미하지 않은 결과가 나오면 모형이 잘 만들어졌다고 할 수 있습니다.
- 아래와 같이 신뢰구간이 0을 포함하고 p-value > 0.05 로 통계적으로 유의하지 않았기 때문에 모형이 잘 만들어졌다고 판단했습니다.
    
    ![png](/images/2023-10-03-CausalImpact_files/Untitled 4.png) 
    
<br>

### 5-2. Back-test의 한계점

- 모델이 잘 만들어졌는지를 확인하려면 여러 기간으로 여러번 back-test를 해보는것이 좋은데 활용할 수 있는 데이터 자체가 많지 않고, 이벤트 적용 이후 기간은 더더욱 짧아서 여러차례 back-test를 하는데 한계가 있었습니다.
- 그리고 back-test를 할때는 어떠한 개입이 없었던 기간으로 해야하는데, 초기 서비스의 경우 여러 마케팅을 하기도하고 빠르게 기능 배포도 이루어지다보니 
아무 개입이 없었던 날짜 자체를 찾기가 어려울수도 있습니다.
    - 만약, 다른 개입이 있던 날짜로 back-test를 하게되면 유의미하게 감소 혹은 증가했다는 결과를 보게 될 수 있습니다.


<br>
<br>

# 6. 그 외

**< Hyper parameter 튜닝 >**

아래와 같은 파라미터들이 있었는데, 기존 default model 로도 결과 해석에 문제가 없다고 판단하여 추가하지는 않았습니다.

- seasonality를 반영하기엔 데이터 기간이 짧음.

```
# parameter
- model_args
  - standardize
  - prior_level_sd
  - fit_method
  - nseasons
  - season_duration
- alpha

# parameter 설명
- nseasons을 7로두고 seasonal_duration 을 1로두면 weekly seasonality가 있고, 각각의 데이터포인트가 하루를 나타냄.
  nseasons을 12로두고 seasonal_duration 을 30 로두면 Monthly seasonality가 있고, 매 30일이 한달을 나타냄.
- prior_level_sd : 잔차가 작고, 안정적인 시계열이 아닐경우 0.1로 세팅 (default=0.01)

# code example
ci = CausalImpact(ci_data_zscore, pre_period, post_period, model_args={'nseasons':7 ,'seasonal_duration':1})
```

<br>
<br>

# Lessons Learned

---

- 결과값이 통계적으로 유의하게 나오게 하기위해(p-value<0.05 이면서 신뢰구간이 0을 포함하지 않게) 여러가지 공변량을 계속 추가하는것이 데이터를 선택 편향해서 해석하는게 아닐지 우려가 되었습니다.
- 모델을 실행할때마다 결과가 약간씩 다르게 나오기도 하기 때문에, 한번의 실행으로 믿고 싶은 결과를 믿으면 안되고 여러가지 변수를 넣고 빼보면서 실험해보고 , back-test도 진행해본 이후 종합적인 결론을 내는것이 중요합니다.
- 공변량 변수를 선정할때 반응변수와 정말 비슷한 흐름을 띄는지, 상관계수를 확인하는것 외에 다른 방법으로 좀더 면밀하게 검토해서 공변량 변수를 추가하는 방법도 고려해볼 필요가 있습니다.
- Counterfactual 을 모델이 잘 예측하게 하기위해 상관관계가 높은 공변량 변수들을 추가하는것이 도움이 된다는것을 알았습니다.
    - 한 예로, A라는 공변량 변수만 넣었을때는 결과가 통계적으로 유의하지 않다고 나왔는데, 종속변수와 상관관계가 높은 B,C,D 를 공변량으로 더 추가했더니 모델이 더 잘 예측하는것을 확인했습니다.
- 기간을 좀더 확장했을때 효과가 좋았습니다. (고로, 데이터는 많을수록 모델 학습에 도움이 된다…)

<br>
<br>

